{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from nets.model import Model\n",
    "from utils import get_device, get_costs, get_costs_from_D, get_mrcst_costs\n",
    "cost_functions = {'default': get_costs, 'mrcst': get_mrcst_costs, 'from_D': get_costs_from_D}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n",
      "torch.cuda.device_count(): 1\n",
      "device_idxes: [0]\n",
      "devices: [<torch.cuda.device object at 0x00000158877AF550>]\n",
      "device_names: ['NVIDIA GeForce RTX 2070 with Max-Q Design'] \n",
      "\n",
      "torch.cuda.current_device(): 0\n",
      "torch.cuda.device(current_device): <torch.cuda.device object at 0x00000158877AF550>\n",
      "torch.cuda.get_device_name(current_device): NVIDIA GeForce RTX 2070 with Max-Q Design \n",
      "\n",
      "Using device: cuda \n",
      "\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device, device_count = get_device()\n",
    "device, device_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 find satified checkpoint in: pretrained/20221119-000812-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dc2-stpFalse-cfdefault-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-000812-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dc2-stpFalse-cfdefault-nb2500-bs512/99.pt\n",
      "0 find satified checkpoint in: pretrained/20221119-000735-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpFalse-cfmrcst-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-000735-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpFalse-cfmrcst-nb2500-bs512/99.pt\n",
      "0 find satified checkpoint in: pretrained/20221119-000526-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpTrue-cfdefault-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-000526-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpTrue-cfdefault-nb2500-bs512/99.pt\n",
      "0 find satified checkpoint in: pretrained/20221119-001123-gs20-dm256-nh8-nel3-ndl2-df512-lr1e-04-dc2-stpFalse-cfdefault-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-001123-gs20-dm256-nh8-nel3-ndl2-df512-lr1e-04-dc2-stpFalse-cfdefault-nb2500-bs512/99.pt\n",
      "0 find satified checkpoint in: pretrained/20221119-001050-gs20-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpFalse-cfmrcst-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-001050-gs20-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpFalse-cfmrcst-nb2500-bs512/99.pt\n",
      "0 find satified checkpoint in: pretrained/20221119-001144-gs20-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpTrue-cfdefault-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-001144-gs20-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpTrue-cfdefault-nb2500-bs512/99.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_model(load_graph_size, degree_constrain, cost_function_key, is_stp, test_graph_size=None):\n",
    "    \"\"\"\n",
    "    @param grapg_size: int, e.g. 20, 50, 100\n",
    "    @param degree_constrain: None / int > 1\n",
    "    @param cost_function_key: str, e.g. default, mrcst\n",
    "    @param is_stp: bool\n",
    "    @param return: model\n",
    "    \"\"\"\n",
    "    graph_dim = 2\n",
    "    d_model = 256\n",
    "    nhead = 8\n",
    "    num_encoder_layers = 3\n",
    "    num_decoder_layers = 2\n",
    "    dim_feedforward = 128 if load_graph_size == 100 else 512\n",
    "    lr = 1e-04\n",
    "    cost_function = cost_functions[cost_function_key]\n",
    "    num_batches = 2500\n",
    "    batch_size = 512\n",
    "    target_epoch = None\n",
    "    paths = []\n",
    "    i = 0\n",
    "    for rn in os.listdir('pretrained'):\n",
    "        target_run_name = 'gs{}-dm{}-nh{}-nel{}-ndl{}-df{}-lr{:.0e}-dc{}-stp{}-cf{}-nb{}-bs{}'.format(\n",
    "            load_graph_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, lr, degree_constrain, is_stp, cost_function_key, num_batches, batch_size\n",
    "        )\n",
    "        if rn[16:] == target_run_name:\n",
    "            num_epochs = [int(_.split('.')[0]) for _ in os.listdir('pretrained/{}'.format(rn))]\n",
    "            if not num_epochs:\n",
    "                continue\n",
    "            path = 'pretrained/{}/{}.pt'.format(\n",
    "                rn, max(num_epochs) if not target_epoch else target_epoch\n",
    "            )\n",
    "            print('{} find satified checkpoint in:'.format(i), path)\n",
    "            paths.append(path)\n",
    "            i += 1\n",
    "    if paths:\n",
    "        idx = 0 if len(paths) == 1 else eval(input())\n",
    "        target_path = paths[idx]\n",
    "        print('load checkpoint in:', target_path)\n",
    "    else:\n",
    "        print('do not find satified checkpoint')\n",
    "    if not test_graph_size:\n",
    "        test_graph_size = load_graph_size\n",
    "    model = Model(test_graph_size, graph_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, degree_constrain, is_stp, device=device).eval()\n",
    "    model.load_state_dict(torch.load(target_path)['model_state_dict'])\n",
    "    return model\n",
    "\n",
    "load_model(50, 2, 'default', False)\n",
    "load_model(50, None, 'mrcst', False)\n",
    "load_model(50, None, 'default', True)\n",
    "load_model(20, 2, 'default', False)\n",
    "load_model(20, None, 'mrcst', False)\n",
    "load_model(20, None, 'default', True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, raw, model, cost_function_key, terminal_size, batch_size, sample_size, greedy=True, return_costs=False, return_edges=False):\n",
    "    \"\"\"\n",
    "    @param raw: raw_x of shape (batch_size, graph_size, 2) or D of shape (batch_size, graph_size, graph_size)\n",
    "    \"\"\"\n",
    "    graph_size = x.shape[1]\n",
    "    assert batch_size >= sample_size\n",
    "    assert x.shape[:2] == raw.shape[:2]\n",
    "    assert not cost_function_key == 'from D' or raw.shape[-1] == graph_size\n",
    "    dataset = TensorDataset(x, raw)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size // sample_size)\n",
    "    cost = mean = std = 0\n",
    "    start_time = time.time()\n",
    "    costs_min_list = []\n",
    "    costs_mean_list = []\n",
    "    costs_std_list = []\n",
    "    edges_list = []\n",
    "    with torch.no_grad():\n",
    "        for data, raw_data in dataloader:  # (batch_size, graph_size, 2)\n",
    "            edges, log_prob_sum, lengths, weights_by_step = model(\n",
    "                data, terminal_size=terminal_size, batch_size=batch_size, greedy=greedy, return_weights=True, max_sample_size=sample_size\n",
    "            )  # (batch_size, 2, graph_size - 1)\n",
    "            assert not len(edges) % len(data), 'length error, len(edges): {}, len(data): {}'.format(len(edges), len(data))\n",
    "            assert sample_size == len(edges) // len(data)\n",
    "            costs = cost_functions[cost_function_key](\n",
    "                raw_data.unsqueeze(dim=1).expand(-1, sample_size, -1, -1).clone().view(-1, graph_size, raw.shape[-1]),\n",
    "                edges\n",
    "            )  # (batch_size * sample_size)\n",
    "            temp = costs.view(-1, sample_size).cpu()\n",
    "            batch_cost_min = temp.min(dim=1)[0]\n",
    "            batch_cost_mean = temp.mean(dim=1)\n",
    "            batch_cost_std =temp.std(dim=1)\n",
    "            if return_edges:\n",
    "                batch_idx = torch.argmin(costs.view(-1, sample_size), dim=1)\n",
    "                batch_edge = edges.view(-1, sample_size, 2, graph_size - 1)[torch.arange(len(costs) // sample_size), batch_idx]\n",
    "            assert  len(data) == len(batch_cost_min) == len(batch_cost_mean) == len(batch_cost_std)\n",
    "            cost += (batch_cost_min).sum()\n",
    "            mean += (batch_cost_mean).sum()\n",
    "            std += (batch_cost_std).sum()\n",
    "            if return_costs:\n",
    "                for c in batch_cost_min:\n",
    "                    costs_min_list.append(c.item())\n",
    "                for c in batch_cost_mean:\n",
    "                    costs_mean_list.append(c.item())\n",
    "                for c in batch_cost_std:\n",
    "                    costs_std_list.append(c.item())\n",
    "            if return_edges:\n",
    "                for e in batch_edge:\n",
    "                    edges_list.append(np.array(e.cpu()))\n",
    "        torch.cuda.empty_cache()\n",
    "    return (\n",
    "        cost / len(dataloader.dataset), \n",
    "        mean / len(dataloader.dataset), \n",
    "        std / len(dataloader.dataset), \n",
    "        (time.time() - start_time) / len(dataloader.dataset), \n",
    "        {\n",
    "            'costs_min_list': costs_min_list,\n",
    "            'costs_mean_list': costs_mean_list,\n",
    "            'costs_std_list': costs_std_list,\n",
    "            'edge_list': edges_list\n",
    "        }\n",
    "    )\n",
    "load_graph_size, test_graph_size = 50, 20\n",
    "num_test, batch_size, sample_size = 3, 8, 4  # batch_size of dataloader is 8 / 4 = 2, which divide data into batches of [2, 1]\n",
    "\n",
    "with open('data/random/{}_test_seed1234.pkl'.format(test_graph_size), 'rb') as f:\n",
    "    x = torch.tensor(np.load(f, allow_pickle=True), dtype=torch.float32).to(device)[:num_test]  # (batch_size, graph_size, dim)\n",
    "with open('data/random/{}_test_seed1234.pkl'.format(test_graph_size), 'rb') as f:\n",
    "    raw_x = torch.tensor(np.load(f, allow_pickle=True), dtype=torch.float32).to(device)[:num_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 find satified checkpoint in: pretrained/20221119-000812-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dc2-stpFalse-cfdefault-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-000812-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dc2-stpFalse-cfdefault-nb2500-bs512/99.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.2387),\n",
       " tensor(3.2995),\n",
       " tensor(0.0556),\n",
       " 0.6177262465159098,\n",
       " {'costs_min_list': [3.1079583168029785,\n",
       "   3.2559947967529297,\n",
       "   3.352095127105713],\n",
       "  'costs_mean_list': [3.1366958618164062,\n",
       "   3.3844077587127686,\n",
       "   3.3772921562194824],\n",
       "  'costs_std_list': [0.03780844062566757,\n",
       "   0.09447567909955978,\n",
       "   0.034585416316986084],\n",
       "  'edge_list': [array([[12,  4,  9, 17, 12, 15,  2, 16,  6,  1, 13, 19, 18,  3,  0, 14,\n",
       "           10,  7,  5],\n",
       "          [ 4,  9, 17,  6, 15,  2, 16,  8,  1, 13, 19, 18,  3,  0, 14, 10,\n",
       "            7,  5, 11]], dtype=int64),\n",
       "   array([[17, 13,  7,  8,  9, 15,  2, 18,  4, 10,  5,  1,  3, 19,  0, 14,\n",
       "           12, 16, 11],\n",
       "          [13,  7,  8,  9, 15,  2, 18,  4, 10,  5,  1,  3, 19,  0, 14, 12,\n",
       "           16, 11,  6]], dtype=int64),\n",
       "   array([[ 5, 13,  9, 14, 16,  6,  8,  3, 10, 19,  1,  5,  0, 11,  4,  2,\n",
       "           17,  7, 18],\n",
       "          [13,  9, 14, 16,  6,  8,  3, 10, 19,  1, 11,  0,  7,  4,  2, 17,\n",
       "           12, 18, 15]], dtype=int64)]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dcmst (d=2)\n",
    "degree_constrain, cost_function_key, terminal_size = 2, 'default', test_graph_size\n",
    "model = load_model(load_graph_size, degree_constrain, cost_function_key, False, test_graph_size=test_graph_size)\n",
    "test(x, raw_x, model, cost_function_key, terminal_size, batch_size, sample_size, greedy=True, return_costs=True, return_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 find satified checkpoint in: pretrained/20221119-000735-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpFalse-cfmrcst-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-000735-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpFalse-cfmrcst-nb2500-bs512/99.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(131.4133),\n",
       " tensor(131.4133),\n",
       " tensor(0.),\n",
       " 0.04753939310709635,\n",
       " {'costs_min_list': [120.3918228149414,\n",
       "   137.89297485351562,\n",
       "   135.95506286621094],\n",
       "  'costs_mean_list': [120.3918228149414,\n",
       "   137.89297485351562,\n",
       "   135.95506286621094],\n",
       "  'costs_std_list': [0.0, 0.0, 0.0],\n",
       "  'edge_list': [array([[ 6,  6,  1,  1, 10, 10,  7, 13,  1,  1, 10,  6, 17, 17, 14, 17,\n",
       "            7,  2,  7],\n",
       "          [17,  1, 13, 10,  7, 14,  5,  3, 19, 18,  0,  9, 12, 15, 11,  4,\n",
       "            2, 16,  8]], dtype=int64),\n",
       "   array([[ 6, 11,  4,  4,  4,  5, 18,  4, 10,  4,  4, 18, 11,  4, 18,  4,\n",
       "           18,  7, 15],\n",
       "          [11,  4, 18, 10,  5,  1,  2,  3, 17, 19,  0, 15, 16, 14, 13, 12,\n",
       "            7,  8,  9]], dtype=int64),\n",
       "   array([[10,  7,  7,  0,  0,  4,  8,  0,  0,  0, 10,  4,  7, 15,  5, 11,\n",
       "           10,  4, 17],\n",
       "          [ 7,  0,  4,  8, 16, 11,  6,  5, 14,  9,  3, 17, 15, 18, 13,  1,\n",
       "           19,  2, 12]], dtype=int64)]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mrcst\n",
    "degree_constrain, cost_function_key, terminal_size = None, 'mrcst', test_graph_size\n",
    "model = load_model(load_graph_size, degree_constrain, cost_function_key, False, test_graph_size=test_graph_size)\n",
    "test(x, raw_x, model, cost_function_key, terminal_size, batch_size, sample_size, greedy=True, return_costs=True, return_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 find satified checkpoint in: pretrained/20221119-000526-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpTrue-cfdefault-nb2500-bs512/99.pt\n",
      "load checkpoint in: pretrained/20221119-000526-gs50-dm256-nh8-nel3-ndl2-df512-lr1e-04-dcNone-stpTrue-cfdefault-nb2500-bs512/99.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.4226),\n",
       " tensor(0.4226),\n",
       " tensor(0.),\n",
       " 0.0059884389241536455,\n",
       " {'costs_min_list': [0.2954133450984955,\n",
       "   0.4907519221305847,\n",
       "   0.4814966320991516],\n",
       "  'costs_mean_list': [0.2954133450984955,\n",
       "   0.4907519221305847,\n",
       "   0.4814966320991516],\n",
       "  'costs_std_list': [0.0, 0.0, 0.0],\n",
       "  'edge_list': [array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "         dtype=int64),\n",
       "   array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "         dtype=int64),\n",
       "   array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "         dtype=int64)]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stp\n",
    "degree_constrain, cost_function_key, terminal_size = None, 'default', 2\n",
    "model = load_model(load_graph_size, degree_constrain, cost_function_key, True, test_graph_size=test_graph_size)\n",
    "test(x, raw_x, model, cost_function_key, terminal_size, batch_size, sample_size, greedy=True, return_costs=True, return_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
